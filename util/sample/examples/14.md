#util/sample/examples/14 Confine [simulation](#util/sim) states to observed ([logged](#logger)) distributions using [domain](#///domains) `dist(observed_sample)`. Weights (densities) are based on a two-sample [Kolmogorov-Smirnov statistic](https://en.wikipedia.org/wiki/Kolmogorov–Smirnov_test#Kolmogorov–Smirnov_statistic) (see `ks2_density` in #util/stat) with both sides approximated using finite samples from repeated simulations and fixed observations. Longer simulations produce sharper weights and can also improve efficiency & parallelism (when using workers). Weight accumulation (or maximization) can be used to further approximate longer simulations if maximum-weight/likelihood estimates are sufficient and over-concentrated posteriors (around MAP point) with fixed-tail convergence (based on most recent updates only, default for accumulation or optimization) are acceptable.
```js:js_input

// init state (vars & params) starting at -X days, to be simulated to now
// longer sim = sharper weights, higher efficiency, higher parallelism
// shorter sim = relaxed weights, faster updates, more convergence checks
// sim length (days) can be tied to weight relaxation parameter r∈(0,1]
let x = state({
  t: _6am - round(30 * max(.25, context.r)), // start time
  alice: { awake: false }, // alice is asleep at start time
  _events: [] // enable simulated event history, used below
})
const h_wake  = around(sample(between(6,10)), sample(between(0,2)))
const h_sleep = around(sample(between(0,3)),  sample(between(0,2)))
simulate(x, now(), [
  wake(x.alice, daily(h_wake)),
  sleep(x.alice, daily(h_sleep))
], { allow_next:true }) // simulate to next event >now
predict(last_event_name(x)) <<- next_event_name
const sleep_lengths = hours_between_events(x, 'alice.sleep', 'alice.wake')
accumulate( // accumulate weights across runs, see notes below
  confine(event_hours(x, 'alice.wake'), logged_wake_hours),
  confine(event_hours(x, 'alice.sleep'), logged_sleep_hours),
  confine(sleep_lengths, logged_sleep_lengths)
)
predict(mean(sleep_lengths))
predict(stdev(sleep_lengths))

```
```js:js_removed

// WEIGHT ACCUMULATION OR MAXIMIZATION METHODS
// note all these methods over-concentrate posterior around MAP point
// these methods assume independent samples, even though logged samples reused
//
// accumulate(
//   confine(event_hours(x, 'alice.wake'), logged_wake_hours),
//   confine(event_hours(x, 'alice.sleep'), logged_sleep_hours),
//   confine(sleep_lengths, logged_sleep_lengths)
// )
//
// accumulate(weight(
//   logged_wake_hours._log_p(event_hours(x, 'alice.wake')) +
//   logged_sleep_hours._log_p(event_hours(x, 'alice.sleep')) +
//   logged_sleep_lengths._log_p(sleep_lengths)
// ))
//
// maximize(
//   logged_wake_hours._log_p(event_hours(x, 'alice.wake')) +
//   logged_sleep_hours._log_p(event_hours(x, 'alice.sleep')) +
//   logged_sleep_lengths._log_p(sleep_lengths)
// )
//
// USING EVENT HISTORY (x._events)
// note we use x._events in place of custom stats tracked via event functions
// simplifies event functions, and is a major overhead in basic benchmarks
//
const wake = (x, ft) => _if(x=>!x.awake, ft, x=>{ x.awake=true }, x, 'wake')
const sleep = (x, ft) => _if(x=>x.awake, ft, x=>{ x.awake=false }, x, 'sleep')

const last_event_name = x => last(x._events)._source._name
const event_hours = (x, name) => remove(x._events.map(e=>{
  if (e._source._name == name) return (e.t - ~~e.t) * 24
}))
const hours_between_events = (x, start, end) => remove(x._events.map((e,j,eJ)=>{
  if (j>0 && e._source._name == end && eJ[j-1]._source._name == start)
    return (e.t - eJ[j-1].t) * 24
}))

// note event_log(…) is NOT available on workers as it depends on cached state (event log) on _item(#logger), so we simply define context as a function (that returns a context object), which allows event-log-based arrays to be pre-computed on main thread and then passed along to workers via options.context
const context = () => ({
  logged_wake_hours: dist(event_log('wake','h')),
  logged_sleep_hours: dist(event_log('sleep','h')),
  logged_sleep_lengths: dist(event_log(undefined, (e,j,eJ) => {
    if (e.keyword == 'wake' && eJ[j+1]?.keyword == 'sleep')
      return (e.t - eJ[j+1].t) * 24
  }))
})

const _sample_options = {
  stats:'mks ess elw r t mean.maximize median.maximize',
  context, // as function defined above
  max_time:10000,
  table:true,
  plot:true,
  // size:1, // debug
  async:true,
  workers:navigator.hardwareConcurrency, // ~optimal for time/sample (tpsa)
}

```
#_util #_logger #_async