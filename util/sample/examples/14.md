#util/sample/examples/14 Confine [simulation](#util/sim) states to observed ([logged](#logger)) distributions using [domain](#///domains) `dist(observed_sample)`. Weights (densities) are based on a two-sample [Kolmogorov-Smirnov statistic](https://en.wikipedia.org/wiki/Kolmogorov–Smirnov_test#Kolmogorov–Smirnov_statistic) (see `ks2_density` in #util/stat) with both sides approximated using finite samples from repeated simulations and fixed observations. Longer simulations produce sharper weights and can also improve efficiency & parallelism (when using workers). Weight accumulation (or maximization) can be used to further approximate longer simulations if maximum-weight/likelihood estimates are sufficient and over-concentrated posteriors (around MAP point) with fixed-tail convergence (based on most recent updates only, default for accumulation or optimization) are acceptable.
```js:js_input

// init state (vars & params) starting at -X days, to be simulated to now
const [vars, params] = sleep_wake_state('olcan', { t: _6am - 90 })
merge(params.olcan, { // sample & merge parameters to be inferred
  wake_hour:  { mean: sample(between(6,10)), stdev: sample(between(0,2)) },
  sleep_hour: { mean: sample(between(-1,3)), stdev: sample(between(0,2)) },
})
const x = state(vars, params, { events:true }) // enable x._events used below
const events = sleep_wake_events(x, 'olcan') // init events to mutate state
simulate(x, now(), events, { allow_next:true }) // simulate to next event >now
predict(last_event_name(x), 'next event') // last simulated event is next
const sleep_lengths = hours_between_events(x, 'olcan.sleep', 'olcan.wake')
accumulate( // accumulate weights across runs, see notes below
  confine(event_hours(x, 'olcan.wake'), logged_wake_hours),
  confine(event_hours(x, 'olcan.sleep'), logged_sleep_hours),
  confine(sleep_lengths, logged_sleep_lengths)
)
predict(mean(sleep_lengths))
predict(stdev(sleep_lengths))

```
```js:js_removed

// performance stats (for 10 days of sim)
// before _State: pps is ~45k, aps ~20k
// _State w/o tracking, w/ array state for sleep/wake times: ~80%
// _State using _events array: ~90%
// _State using _events array, w/ tracking: ~80%

// alternative methods for weight accumulation or maximization
// note all these methods over-concentrate posterior around MAP point
// these methods assume independent samples, even though logged samples reused
//
// accumulate(
//   confine(event_hours(x, 'olcan.wake'), logged_wake_hours),
//   confine(event_hours(x, 'olcan.sleep'), logged_sleep_hours),
//   confine(sleep_lengths, logged_sleep_lengths)
// )
//
// accumulate(weight(
//   logged_wake_hours._log_p(event_hours(x, 'olcan.wake')) +
//   logged_sleep_hours._log_p(event_hours(x, 'olcan.sleep')) +
//   logged_sleep_lengths._log_p(sleep_lengths)
// ))
//
// maximize(
//   logged_wake_hours._log_p(event_hours(x, 'olcan.wake')) +
//   logged_sleep_hours._log_p(event_hours(x, 'olcan.sleep')) +
//   logged_sleep_lengths._log_p(sleep_lengths)
// )

function sleep_wake_state(name, vars={}, params={}) {
  assign(vars[name] ??= {}, { awake: false }) // assume asleep initially
  assign(params[name] ??= {}, {
    wake_hour: { mean: 8, stdev: 1 },
    sleep_hour: { mean: 0, stdev: 1 },
  })
  return [vars, params]
}
function sleep_wake_events(x, name, events=[]) {
  x = x[name] // to avoid repeated lookup of same object
  const sleep = ft => _if(_=>x.awake, ft, _=>{ x.awake=false })
  const wake  = ft => _if(_=>!x.awake, ft, _=>{ x.awake=true })
  const around_hour = h => around(h.mean, h.stdev)
  events.push(...name_events({
    [name+'.sleep']: sleep(daily(_=>around_hour(x.sleep_hour))),
    [name+'.wake']: wake(daily(_=>around_hour(x.wake_hour))),
  }))
  return events
}
const last_event_name = x => last(x._events)._source._name
const event_hours = (x, name) => remove(x._events.map(e=>{
  if (e._source._name == name) return (e.t - ~~e.t) * 24
}))
const hours_between_events = (x, start, end) => remove(x._events.map((e,j,eJ)=>{
  if (j>0 && e._source._name == end && eJ[j-1]._source._name == start)
    return (e.t - eJ[j-1].t) * 24
}))

// note event_log(…) is NOT available on workers as it depends on cached state (event log) on _item(#logger), so we simply define context as a function (that returns a context object), which allows event-log-based arrays to be pre-computed on main thread and then passed along to workers via options.context
const context = () => ({
  logged_wake_hours: dist(event_log('wake','h')),
  logged_sleep_hours: dist(event_log('sleep','h')),
  logged_sleep_lengths: dist(event_log(undefined, (e,j,eJ) => {
    if (e.keyword == 'wake' && eJ[j+1]?.keyword == 'sleep')
      return (e.t - eJ[j+1].t) * 24
  }))
})

const _sample_options = {
  stats:'mks ess elw r t mean.maximize median.maximize',
  context, // as function defined above
  max_time:10000,
  table:true,
  plot:true,
  // size:1, // debug
  async:true,
  // note safari can report smaller concurrency
  // also having 2x workers seems to improve parallelism
  workers:navigator.hardwareConcurrency * 2,
}

```
#_util #_logger #_async